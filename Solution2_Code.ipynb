{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplearning with Transformer Architectures\n",
    "\n",
    "There are three sections to this implementation.\n",
    "- Relevant Imports and PIP Installs (self explanatory)\n",
    "- Dataset class and preprocessing function. Creates and stores the mpnet embeddings on the pre-processed dataset.\n",
    "- Classifier Definition. Defines the ensemble as well as the binary classifier members.\n",
    "- Functions for training and testing.\n",
    "- The Notebook \"Engine\", which controls which cells will execute. For example sometimes we might want to skip training or eval etc.\n",
    "- Demo block (This requires running the previous cells to define the needed functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Imports and PIP Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install sentence-transformers\n",
    "!pip3 inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all relevant modules\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class and Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preprocessing\n",
    "\n",
    "def preprocess_line(line: str, params: set, tokenizer=None) -> list[str]:\n",
    "    '''\n",
    "    Preprocesses a line of text\n",
    "\n",
    "    :param line:\n",
    "    :param params:\n",
    "    :return:\n",
    "\n",
    "    Program flow:\n",
    "        If the line contains an email, trims out the email header\n",
    "        Tokenises the line\n",
    "        Applies various transformations\n",
    "            Removes stop words\n",
    "            Stems\n",
    "            Lemmatises\n",
    "            Remvoes non-alphanumeric characters\n",
    "            Sets all lowercase\n",
    "        Returns the list of tokens\n",
    "    '''\n",
    "\n",
    "    if \"trim email\" in params:\n",
    "        if \"-- Forwarded by\" in line:\n",
    "            before_email = line.split(\"-\")[0].strip()\n",
    "            email = \"-\" + line.split(\"-\", 1)[1] if \"-\" in line else \"\"\n",
    "            email_subject = email.split(\"Subject:\")[-1].strip() # if there's no subject, this keeps the whole email\n",
    "            line = before_email + \" \" + email_subject\n",
    "            line = line.strip()\n",
    "        line\n",
    "    \n",
    "    if tokenizer == None:\n",
    "        tokens = nltk.tokenize.word_tokenize(line)\n",
    "    else:\n",
    "        tokens = tokenizer.tokenize(line)\n",
    "        starts_with_space_labels = [1 if \"Ġ\" in token else 0 for token in tokens]\n",
    "        tokens = [token.replace(\"Ġ\",\"\") if \"Ġ\" in token else token for token in tokens ]\n",
    "        if len(tokens) != len(starts_with_space_labels):\n",
    "            print(len(tokens))\n",
    "            print(len(starts_with_space_labels))\n",
    "            raise Exception(\"A token has been removed, labels dont align\")\n",
    "\n",
    "    operations = {\n",
    "        \"stop words\": lambda tokens: [token if token.lower() not in nltk.corpus.stopwords.words('english') else \"\" for token in tokens],\n",
    "        \"stem\": lambda tokens: [nltk.PorterStemmer().stem(token) for token in tokens],\n",
    "        \"lemmatise\": lambda tokens: [nltk.WordNetLemmatizer().lemmatize(token) for token in tokens],\n",
    "        \"alphanumeric\": lambda tokens: [\"\".join(filter(str.isalnum, token)) for token in tokens],\n",
    "        \"lowercase\": lambda tokens: [token.lower() for token in tokens]\n",
    "    }\n",
    "\n",
    "    # Apply each operation if we define it in the params set\n",
    "    for key, action in operations.items():\n",
    "        if key in params:\n",
    "            tokens = action(tokens)\n",
    "    \n",
    "    if tokenizer == None:\n",
    "        return [token for token in tokens if token != \"\"]\n",
    "    else:\n",
    "        if len(tokens) != len(starts_with_space_labels):\n",
    "            print(len(tokens))\n",
    "            print(len(starts_with_space_labels))\n",
    "            raise Exception(\"A token has been removed, labels dont align\")\n",
    "        return [tokens[i] if not starts_with_space_labels[i] else \"\".join([\"Ġ\", tokens[i]]) for i in range(len(tokens))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create dataset and data loader\n",
    "\n",
    "class reformattedDataset(Dataset):\n",
    "    def __init__(self, df_name, parameters, reset_cache=False):\n",
    "        # Name is in form <path>/<name>.csv\n",
    "        name = df_name.split(\"/\")[-1]\n",
    "        name = name.split(\".\")[0]\n",
    "        print(name)\n",
    "\n",
    "        df = pd.read_csv(df_name)\n",
    "        \n",
    "        # load stores embeddings if found\n",
    "        if os.path.exists(f\"Cached_MPNet/{name}_output1.pt\") and os.path.exists(f\"Cached_MPNet/{name}_output2.pt\") and reset_cache == False:\n",
    "            print(\"Loading cached MPNet outputs...\")\n",
    "            loaded_o1 = torch.load(f\"Cached_MPNet/{name}_output1.pt\", weights_only=True, map_location=device)\n",
    "            self.output1 = torch.stack([torch.tensor(t) for t in loaded_o1])\n",
    "            self.output2 = torch.stack([torch.tensor(t) for t in torch.load(f\"Cached_MPNet/{name}_output2.pt\", weights_only=True, map_location=device)])\n",
    "            print(f\"Successfully loaded {len(self.output1)} MPNet outputs\")\n",
    "\n",
    "            self.labels = df[\"label\"][:len(self.output1)].reset_index(drop=True)\n",
    "\n",
    "        # create embeddings if not found\n",
    "        else:\n",
    "            mpnet = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "            texts1 = df[\"text_1\"].astype(str).tolist()\n",
    "            texts2 = df[\"text_2\"].astype(str).tolist()\n",
    "\n",
    "            self.output1 = torch.tensor(mpnet.encode(texts1, batch_size=16, convert_to_tensor=True, show_progress_bar=True))\n",
    "            self.output2 = torch.tensor(mpnet.encode(texts2, batch_size=16, convert_to_tensor=True, show_progress_bar=True))\n",
    "            \n",
    "            self.labels = df[\"label\"]\n",
    "\n",
    "            torch.save(self.output1, f\"Cached_MPNet/{name}_output1.pt\")\n",
    "            torch.save(self.output2, f\"Cached_MPNet/{name}_output2.pt\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.output1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        return self.output1[i], self.output2[i], torch.tensor(self.labels.iloc[i], dtype=torch.float)\n",
    "\n",
    "# same as above class, except no label\n",
    "class MPNetTestDataset(Dataset):\n",
    "    def __init__(self, df_name, parameters, reset_cache=False):\n",
    "        # Name is in form <path>/<name>.csv\n",
    "        name = df_name.split(\"/\")[-1]\n",
    "        name = name.split(\".\")[0]\n",
    "        print(name)\n",
    "\n",
    "        df = pd.read_csv(df_name)\n",
    "        \n",
    "        if os.path.exists(f\"Cached_MPNet/{name}_output1.pt\") and os.path.exists(f\"Cached_MPNet/{name}_output2.pt\") and reset_cache == False:\n",
    "            print(\"Loading cached MPNet outputs...\")\n",
    "            loaded_o1 = torch.load(f\"Cached_MPNet/{name}_output1.pt\", weights_only=True, map_location=device)\n",
    "            self.output1 = torch.stack([torch.tensor(t) for t in loaded_o1])\n",
    "            self.output2 = torch.stack([torch.tensor(t) for t in torch.load(f\"Cached_MPNet/{name}_output2.pt\", weights_only=True, map_location=device)])\n",
    "            print(f\"Successfully loaded {len(self.output1)} MPNet outputs\")\n",
    "\n",
    "        else:\n",
    "            mpnet = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "\n",
    "            texts1 = df[\"text_1\"].astype(str).tolist()\n",
    "            texts2 = df[\"text_2\"].astype(str).tolist()\n",
    "\n",
    "            self.output1 = torch.tensor(mpnet.encode(texts1, batch_size=16, convert_to_tensor=True, show_progress_bar=True))\n",
    "            self.output2 = torch.tensor(mpnet.encode(texts2, batch_size=16, convert_to_tensor=True, show_progress_bar=True))\n",
    "            \n",
    "            torch.save(self.output1, f\"Cached_MPNet/{name}_output1.pt\")\n",
    "            torch.save(self.output2, f\"Cached_MPNet/{name}_output2.pt\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.output1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        return self.output1[i], self.output2[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our architecture\n",
    "\n",
    "class classifierMPNet(nn.Module):\n",
    "    def __init__(self,child_num):\n",
    "        super(classifierMPNet, self).__init__()\n",
    "\n",
    "        self.child_num = child_num\n",
    "\n",
    "        # add our custom binary classifier layer to end\n",
    "        self.fc1 = nn.Linear(768*4 + 1, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 1)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            self.fc1,\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.Dropout(0.3),\n",
    "            self.fc2, \n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Dropout(0.3),\n",
    "            self.fc3\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid() #to convert classifier output to probability\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # use pre computed MPNet tensors\n",
    "        cos_sim = nn.functional.cosine_similarity(input1, input2, dim=1).unsqueeze(1)\n",
    "        combined_inputs = torch.cat((input1, input2, torch.abs(input1-input2), input1*input2, cos_sim), dim=1)\n",
    "\n",
    "        # pass result through our appended classifier layers\n",
    "        classifier_output = self.classifier(combined_inputs)\n",
    "        return classifier_output\n",
    "\n",
    "\n",
    "class AverageClassifier(nn.Module):\n",
    "    def __init__(self, children=5):\n",
    "        super(AverageClassifier, self).__init__()\n",
    "\n",
    "        # create ensemble members\n",
    "        self.clfs = nn.ModuleList([classifierMPNet(child_num) for child_num in range(children)])\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        outs = [clf(input1, input2) for clf in self.clfs]\n",
    "        stack = torch.stack(outs, dim=0)\n",
    "        return torch.mean(stack, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier():\n",
    "    # Hyper-Parameters:\n",
    "    batch_size = 64\n",
    "    lr = 0.001\n",
    "    epochs = 40\n",
    "    threshold = 0\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    num_children = 5\n",
    "    model = AverageClassifier(num_children).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimiser = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    train_ds = reformattedDataset(\"Data/train.csv\", parameters={}, reset_cache=False)\n",
    "    val_ds = reformattedDataset(\"Data/dev.csv\", parameters={}, reset_cache=False)\n",
    "    val_dl = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # split training dataset into subsets, one for each child\n",
    "    subset_ratio = 0.8\n",
    "    train_ds_splits = []\n",
    "    for _ in range(num_children):\n",
    "        indices = np.random.choice(len(train_ds), int(len(train_ds) * subset_ratio), replace=True)\n",
    "        subset = Subset(train_ds, indices)\n",
    "        train_ds_splits.append(subset)\n",
    "    \n",
    "    # train each child on its own data split\n",
    "    for child_num, child_model in enumerate(model.clfs):\n",
    "        print(f\"Training child #{child_num + 1}\")\n",
    "\n",
    "        optimiser = torch.optim.AdamW(child_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        child_dl = DataLoader(train_ds_splits[child_num], batch_size=batch_size, shuffle=True)\n",
    "        for epoch in range(epochs):\n",
    "            child_model.train()\n",
    "            loss_list = []\n",
    "\n",
    "            for s1, s2, l in child_dl:\n",
    "                s1, s2, l = s1.to(device), s2.to(device), l.to(device)\n",
    "\n",
    "                optimiser.zero_grad()\n",
    "                output = child_model(s1, s2).reshape(l.shape[0]) \n",
    "                loss = criterion(output, l)\n",
    "                loss_list.append(loss.detach().cpu().numpy()) \n",
    "                loss.backward() \n",
    "                optimiser.step()\n",
    "            \n",
    "            print(f\"Child: {child_num+1}, Epoch {epoch+1}, Loss: {np.mean(loss_list)}\")\n",
    "\n",
    "        # eval the child\n",
    "        loss_list = []\n",
    "        preds = []\n",
    "        true_labels = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for s1, s2, l in val_dl:\n",
    "                s1, s2, l = s1.to(device), s2.to(device), l.to(device)\n",
    "                output = model(s1, s2).reshape(l.shape[0])\n",
    "                loss = criterion(output, l)\n",
    "                loss_list.append(loss.detach().cpu().numpy())\n",
    "                preds.append(1 if output[0] > threshold else 0)\n",
    "                true_labels.append(l.detach().cpu().numpy())\n",
    "\n",
    "        correct = 0\n",
    "        TPs, FPs, FNs, TNs = 0, 0, 0, 0\n",
    "        for j in range(len(true_labels)):\n",
    "            if true_labels[j] == preds[j]:\n",
    "                correct += 1\n",
    "                if true_labels[j] == 1:\n",
    "                    TPs += 1\n",
    "                else:\n",
    "                    TNs += 1\n",
    "            else:\n",
    "                if true_labels[j] == 1:\n",
    "                    FNs += 1\n",
    "                else:\n",
    "                    FPs += 1\n",
    "\n",
    "        accuracy = correct / len(true_labels)\n",
    "        recall = 0 if TPs + FNs == 0 else TPs / (TPs + FNs)\n",
    "        precision = 0 if TPs + FPs == 0 else TPs / (TPs + FPs)\n",
    "        f1 = 0 if precision + recall == 0 else 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        print(f\"Testing Stats for Epoch {epoch+1}\")\n",
    "        print(f\"    Mean Loss: {np.mean(loss_list)}\")\n",
    "        print(f\"    Accuracy: {accuracy}\")\n",
    "        print(f\"    _____________________________\")\n",
    "        print(f\"    |True\\Pred|Positive|Negative|\")\n",
    "        print(f\"    |---------|--------|--------|\")\n",
    "        print(f\"    |Positive |TPs: {TPs}|FNs: {FNs}|\")\n",
    "        print(f\"    |---------|--------|--------|\")\n",
    "        print(f\"    |Negative |FPs: {FPs}|TNs: {TNs}|\")\n",
    "        print(f\"    |---------|--------|--------|\")\n",
    "        print(f\"    \")\n",
    "        print(f\"    Precision: {precision}\")\n",
    "        print(f\"    Recall: {recall}\")\n",
    "        print(f\"    F1 Score: {f1}\")\n",
    "\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a finished trained model\n",
    "def eval_classifier(model):\n",
    "    val_ds = reformattedDataset(\"Data/dev.csv\", parameters={}, reset_cache=False)\n",
    "    val_dl = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    threshold = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for s1, s2, l in val_dl:\n",
    "            s1, s2, l = s1.to(device), s2.to(device), l.to(device)\n",
    "            output = model(s1, s2).reshape(l.shape[0])\n",
    "            loss = criterion(output, l)\n",
    "            loss_list.append(loss.detach().cpu().numpy())\n",
    "            preds.append(1 if output[0] > threshold else 0)\n",
    "            true_labels.append(l.detach().cpu().numpy())\n",
    "\n",
    "    correct = 0\n",
    "    TPs, FPs, FNs, TNs = 0, 0, 0, 0\n",
    "    for j in range(len(true_labels)):\n",
    "        if true_labels[j] == preds[j]:\n",
    "            correct += 1\n",
    "            if true_labels[j] == 1:\n",
    "                TPs += 1\n",
    "            else:\n",
    "                TNs += 1\n",
    "        else:\n",
    "            if true_labels[j] == 1:\n",
    "                FNs += 1\n",
    "            else:\n",
    "                FPs += 1\n",
    "\n",
    "    accuracy = correct / len(true_labels)\n",
    "    recall = 0 if TPs + FNs == 0 else TPs / (TPs + FNs)\n",
    "    precision = 0 if TPs + FPs == 0 else TPs / (TPs + FPs)\n",
    "    f1 = 0 if precision + recall == 0 else 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(f\"Testing Stats for MPNet Classifer (Threshold: {threshold})\")\n",
    "    print(f\"    Mean Loss: {np.mean(loss_list)}\")\n",
    "    print(f\"    Accuracy: {accuracy}\")\n",
    "    print(f\"    _____________________________\")\n",
    "    print(f\"    |True\\Pred|Positive|Negative|\")\n",
    "    print(f\"    |---------|--------|--------|\")\n",
    "    print(f\"    |Positive |TPs: {TPs}|FNs: {FNs}|\")\n",
    "    print(f\"    |---------|--------|--------|\")\n",
    "    print(f\"    |Negative |FPs: {FPs}|TNs: {TNs}|\")\n",
    "    print(f\"    |---------|--------|--------|\")\n",
    "    print(f\"    \")\n",
    "    print(f\"    Precision: {precision}\")\n",
    "    print(f\"    Recall: {recall}\")\n",
    "    print(f\"    F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(model, data_path):\n",
    "    test_ds = MPNetTestDataset(data_path, parameters={}, reset_cache=False)\n",
    "    test_dl = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss_list = []\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    threshold = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for s1, s2 in test_dl:\n",
    "            s1, s2 = s1.to(device), s2.to(device)\n",
    "\n",
    "            output = model(s1, s2)\n",
    "            preds.append(1 if output[0] > threshold else 0)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook \"Engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook parameters - decides which of the next cells actually run\n",
    "generate_new_encodings = False\n",
    "train_new_classifier = False\n",
    "test_the_classifier = False\n",
    "generate_evaluation_csv = False\n",
    "evaluate_classifier = False\n",
    "\n",
    "test_data_path = \"Data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode dataset - run_next usually set to False as this means you can spam shift+enter to get through notebook\n",
    "if generate_new_encodings:\n",
    "    dataset = reformattedDataset(\"Data/train.csv\", parameters={}, reset_cache=True)\n",
    "    val_dataset = reformattedDataset(\"Data/dev.csv\", parameters={}, reset_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new_classifier:\n",
    "    mpnet_classifier = train_classifier()\n",
    "    torch.save(mpnet_classifier.state_dict(), \"Cached_MPNet/trained_classifier_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if evaluate_classifier:\n",
    "    mpnet_classifier = AverageClassifier(children=5).to(device)\n",
    "    mpnet_classifier.load_state_dict(torch.load(\"Cached_MPNet/trained_classifier_weights.pt\", weights_only=True, map_location=device))\n",
    "    eval_classifier(mpnet_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_the_classifier:\n",
    "    mpnet_classifier = AverageClassifier().to(device)\n",
    "    mpnet_classifier.load_state_dict(torch.load(\"Cached_MPNet/trained_classifier_weights.pt\", weights_only=True, map_location=device))\n",
    "    predictions = test_classifier(mpnet_classifier, test_data_path)\n",
    "    preds_df = pd.DataFrame(predictions)\n",
    "    preds_df.to_csv(\"Group_17_B.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_evaluation_csv:\n",
    "    mpnet_classifier = AverageClassifier().to(device)\n",
    "    mpnet_classifier.load_state_dict(torch.load(\"Cached_MPNet/trained_classifier_weights.pt\", weights_only=True, map_location=device))\n",
    "    predictions = test_classifier(mpnet_classifier, \"Data/dev.csv\")\n",
    "    print(\"Done Test\")\n",
    "    predictions = [\"prediction\"] + predictions\n",
    "    preds_df = pd.DataFrame(predictions)\n",
    "    preds_df.to_csv(\"MPNet_Eval.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained weights\n",
    "mpnet_classifier = AverageClassifier().to(device)\n",
    "mpnet_classifier.load_state_dict(torch.load(\"Cached_MPNet/trained_classifier_weights.pt\", weights_only=True, map_location=device))\n",
    "\n",
    "demo_path = \"DEMO_test.csv\"\n",
    "predictions = test_classifier(mpnet_classifier, demo_path)\n",
    "print(\"Created Demo Predictions\")\n",
    "preds_df = pd.DataFrame(predictions, columns=[\"prediction\"])\n",
    "preds_df.to_csv(\"Demo_predictions_sol2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
