{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details of solution 1 implementation\n",
    "\n",
    "Traditional Supervised Machine Learning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspellchecker in /home/benjamin/.local/lib/python3.10/site-packages (0.8.2)\n",
      "Requirement already satisfied: textstat in /home/benjamin/.local/lib/python3.10/site-packages (0.7.5)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from textstat) (59.6.0)\n",
      "Requirement already satisfied: cmudict in /home/benjamin/.local/lib/python3.10/site-packages (from textstat) (1.0.32)\n",
      "Requirement already satisfied: pyphen in /home/benjamin/.local/lib/python3.10/site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: importlib-resources>=5 in /home/benjamin/.local/lib/python3.10/site-packages (from cmudict->textstat) (6.5.2)\n",
      "Requirement already satisfied: importlib-metadata>=5 in /home/benjamin/.local/lib/python3.10/site-packages (from cmudict->textstat) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/benjamin/.local/lib/python3.10/site-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyspellchecker textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/benjamin/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/benjamin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/benjamin/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7a65bc5a2330>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "\n",
    "import spellchecker.spellchecker as spellchecker\n",
    "import textstat\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    # Simple binary classifier\n",
    "    def __init__(self, input_size: int):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        # Input is a parameter and then just has the three layers\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Uses ReLU after each but the final layer\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, transform = None):\n",
    "        # Creates the dataset by converting vectors to tensors\n",
    "        self.data = self.convert_to_tensors(data)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int: # Simple len functionality\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Returns the vector and the label separately\n",
    "        return self.data[idx][0], self.data[idx][1]\n",
    "\n",
    "    def convert_to_tensors(self, data: pd.DataFrame) -> list[list[Tensor]]:\n",
    "        # Takes all but the last value as that is the label and the the label, converting them to tensors\n",
    "        feature_vecs = torch.tensor(data.iloc[:, :-1].values, dtype=torch.float)\n",
    "        labels = torch.tensor(data.iloc[:, -1].values, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # Appends results to a list as they have to come in pairs\n",
    "        ret_list = []\n",
    "        for i in range(len(data)):\n",
    "            ret_list.append([feature_vecs[i], labels[i]])\n",
    "        return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFeatureDataset(Dataset):\n",
    "    # Same as above, just without the label columns (so simpler)\n",
    "    def __init__(self, data: pd.DataFrame, transform = None):\n",
    "        self.data = self.convert_to_tensors(data)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return self.data[idx]\n",
    "\n",
    "    def convert_to_tensors(self, data: pd.DataFrame) -> list[Tensor]:\n",
    "        return torch.tensor(data.values, dtype=torch.float)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vector Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punct_info(words: list[str], text: str, verbose: bool):\n",
    "    # Gets a list of all punctuation, and defines what we call simple punctuation\n",
    "    all_puncts = string.punctuation\n",
    "    simple_puncts = [\",\", \".\", \"!\", \"?\", '\"', \"'\"]\n",
    "\n",
    "    # Initialise the counts\n",
    "    punct_count = 0\n",
    "    simple_punct_count = 0\n",
    "\n",
    "    # Loop through each \"word\" (includes punctuation) to increase counts\n",
    "    for word in words:\n",
    "        if word in all_puncts:\n",
    "            punct_count += 1\n",
    "        if word in simple_puncts:\n",
    "            simple_punct_count += 1\n",
    "\n",
    "    # Gets the amount of complex punctuation\n",
    "    complex_punct_count = punct_count - simple_punct_count\n",
    "\n",
    "    # Calculates the ratio (complexity) of punctuation\n",
    "    punct_complexity = complex_punct_count / punct_count if punct_count != 0 else 0\n",
    "\n",
    "    # Creates the punctuation distribution\n",
    "    punct_dist = np.zeros(len(all_puncts))\n",
    "    for char in all_puncts:\n",
    "        punct_dist[all_puncts.index(char)] = text.count(char)\n",
    "\n",
    "    # Normalises the distribution\n",
    "    punct_dist = np.zeros(len(all_puncts)) if sum(punct_dist) == 0 else punct_dist / sum(punct_dist)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Punctuation count: {punct_count}\")\n",
    "        print(f\"Punctuation complexity: {punct_complexity}\")\n",
    "        print(f\"Punctuation distribution: {punct_dist}\")\n",
    "    \n",
    "    return punct_count, punct_complexity, punct_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt_nn(tagged, verbose: bool = False):\n",
    "    # Set counts to 0\n",
    "    det_count = 0\n",
    "    nn_count = 0\n",
    "\n",
    "    # Checks each word in the tagged dataset to increase counts\n",
    "    for word in tagged:\n",
    "        if word[1] == \"DET\":\n",
    "            det_count += 1\n",
    "        if word[1] == \"NOUN\":\n",
    "            nn_count += 1\n",
    "\n",
    "    # Calculates ratio with div by 0 check\n",
    "    dt_nn_ratio = 0 if nn_count == 0 else det_count / nn_count\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"DT count: {det_count}\")\n",
    "        print(f\"NN count: {nn_count}\")\n",
    "        print(f\"DT:NN ratio: {dt_nn_ratio}\")\n",
    "\n",
    "    return dt_nn_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_len_features(words: list[str], verbose: bool = False):\n",
    "    # Gets the word lengths for every word\n",
    "    word_lengths = [len(word) for word in words]\n",
    "\n",
    "    # Calculates the stats\n",
    "    word_len_range = max(word_lengths) - min(word_lengths)\n",
    "    word_len_q3 = np.percentile(word_lengths, 75)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Word length range: {word_len_range}\")\n",
    "        print(f\"Word length Q3: {word_len_q3}\")\n",
    "\n",
    "    return word_len_range, word_len_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_len_features(sents: list[str], verbose: bool = False):\n",
    "    # Gets the list of sentence lengths\n",
    "    sent_lengths = [len(nltk.word_tokenize(sent)) for sent in sents]\n",
    "\n",
    "    # Simply calculates the stats\n",
    "    sent_len_range = max(sent_lengths) - min(sent_lengths)\n",
    "    sent_len_q3 = np.percentile(sent_lengths, 75)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Sentence length range: {sent_len_range}\")\n",
    "        print(f\"Sentence length Q3: {sent_len_q3}\")\n",
    "\n",
    "    return sent_len_range, sent_len_q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_caps(tagged, sents: list[str], verbose: bool = False):\n",
    "    # Gets a list of all proper nouns\n",
    "    proper_nouns = [word for word in tagged if word[1] == \"NNP\"]\n",
    "    correct_caps_prop_nouns = 0\n",
    "\n",
    "    # Iterates through and checks if they're correctly capitalised\n",
    "    for word in proper_nouns:\n",
    "        if word[0][0].isupper():\n",
    "            correct_caps_prop_nouns += 1\n",
    "\n",
    "    # Calculate the ratio (with check for if there are no proper nounds)\n",
    "    prop_noun_cap_ratio = 0 if len(proper_nouns) == 0 else correct_caps_prop_nouns / len(proper_nouns)\n",
    "\n",
    "    # Loops through each sentence to check first letter\n",
    "    correct_caps_sos = 0\n",
    "    for sent in sents:\n",
    "        if sent[0][0].isupper():\n",
    "            correct_caps_sos = 0\n",
    "\n",
    "    # Calculates ratio\n",
    "    sos_cap_ratio = correct_caps_sos / len(sents)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Proper noun caps ratio: {prop_noun_cap_ratio}\")\n",
    "        print(f\"SOS capitalisation ratio: {sos_cap_ratio}\")\n",
    "\n",
    "    return prop_noun_cap_ratio, sos_cap_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_typo_stats(words: list[str], verbose: bool = False):\n",
    "    # Calculates the typo ratio using pyspellchecker\n",
    "    spell = spellchecker.SpellChecker(\"en\")\n",
    "    misspelled = spell.unknown(words)\n",
    "    typo_ratio = len(misspelled) / len(words)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Typo ratio: {typo_ratio}\")\n",
    "\n",
    "    return typo_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_token(words: list[str], verbose: bool = False):\n",
    "    # Uses set to ensure unique entries to calculate type token ratio\n",
    "    type_token_ratio = len(set(words)) / len(words)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Type-Token Ratio: {type_token_ratio}\")\n",
    "\n",
    "    return type_token_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readability(text: str, verbose: bool = False):\n",
    "    # Simply get the Flesch-Kincaid Grade\n",
    "    readability = textstat.textstat.flesch_kincaid_grade(text)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Reading grade: {reability}\")\n",
    "\n",
    "    return readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Feature Vector Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(text: str, verbose: bool = False) -> np.ndarray:\n",
    "    # Generates the required forms of the text for each calculation\n",
    "    words = text.split()\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    tagged_uni = nltk.pos_tag(words, tagset=\"universal\")\n",
    "    tagged_reg = nltk.pos_tag(words)\n",
    "\n",
    "    # Initialises the empty feature vector\n",
    "    feat_vec = np.ndarray(0, dtype=np.float32)\n",
    "\n",
    "    punc_count, punct_complexity, punct_dist = get_punct_info(words, text, verbose) # Mostly self-explanatory\n",
    "\n",
    "    dt_nn_ratio = get_dt_nn(tagged_uni, verbose)\n",
    "\n",
    "    word_len_range, word_len_q3 = get_word_len_features(words, verbose)\n",
    "\n",
    "    sent_len_range, sent_len_q3 = get_sent_len_features(sents, verbose)\n",
    "\n",
    "    prop_noun_cap_ratio, sos_cap_ratio = check_caps(tagged_reg, sents, verbose)\n",
    "\n",
    "    typo_ratio = get_typo_stats(words, verbose)\n",
    "\n",
    "    type_token_ratio = get_type_token(words, verbose)\n",
    "\n",
    "    readability = get_readability(text, verbose)\n",
    "    \n",
    "    # Appends the results to the vector\n",
    "    feat_vec = np.append(feat_vec, punct_dist)\n",
    "    feat_vec = np.append(feat_vec, punct_complexity)\n",
    "    feat_vec = np.append(feat_vec, dt_nn_ratio)\n",
    "    feat_vec = np.append(feat_vec, word_len_range)\n",
    "    feat_vec = np.append(feat_vec, word_len_q3)\n",
    "    feat_vec = np.append(feat_vec, sent_len_range)\n",
    "    feat_vec = np.append(feat_vec, sent_len_q3)\n",
    "    feat_vec = np.append(feat_vec, prop_noun_cap_ratio)\n",
    "    feat_vec = np.append(feat_vec, sos_cap_ratio)\n",
    "    feat_vec = np.append(feat_vec, typo_ratio)\n",
    "    feat_vec = np.append(feat_vec, type_token_ratio)\n",
    "    feat_vec = np.append(feat_vec, readability)\n",
    "\n",
    "    # Returns the vector\n",
    "    return feat_vec.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vecs(file_path, name):\n",
    "    # Creates the feature vectors that populate the datasets and outputs them for quicker runtime\n",
    "    # feat_vec_size is just the number of data points\n",
    "    feat_vec_size = 43\n",
    "\n",
    "    # Read in text data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Creates 3 * 43 columns, +1 for label\n",
    "    col_names = [f\"fv_1_{i}\" for i in range(feat_vec_size)] + [f\"fv_2_{i}\" for i in range(feat_vec_size)] + [f\"fv_diff_{i}\" for i in range(feat_vec_size)] + [\"label\"]\n",
    "\n",
    "    feat_vec_df = pd.DataFrame(columns=col_names)\n",
    "\n",
    "    # Calculates the feature vector for sentence 1, then sentence 2, then calculates the absolute difference\n",
    "    for i in range(len(df)):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"\\rProcessing pair {i}/{len(df)}\", end=\"\")\n",
    "\n",
    "        label = df[\"label\"]\n",
    "\n",
    "        s1_fv = get_feature_vector(df[\"text_1\"][i]).flatten()\n",
    "        s2_fv = get_feature_vector(df[\"text_2\"][i]).flatten()\n",
    "        fv_diff = np.abs(s1_fv - s2_fv)\n",
    "\n",
    "        # Concatenates together to form a row\n",
    "        row = np.concatenate((s1_fv, s2_fv, fv_diff, [label[i]]), axis=0)\n",
    "\n",
    "        # Appends row to dataframe\n",
    "        feat_vec_df = feat_vec_df._append(pd.DataFrame([row], columns=col_names), ignore_index=True)\n",
    "\n",
    "    # Outputs final dataframe to CSV\n",
    "    feat_vec_df.to_csv(f\"{name}_feature_vectors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vecs_test(file_path, name):\n",
    "    # Creates the feature vectors that populate the datasets and outputs them for quicker runtime\n",
    "    # feat_vec_size is just the number of data points\n",
    "    feat_vec_size = 43\n",
    "\n",
    "    # Read in text data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Defines the same columns as above just without the label \n",
    "    col_names = [f\"fv_1_{i}\" for i in range(feat_vec_size)] + [f\"fv_2_{i}\" for i in range(feat_vec_size)] + [f\"fv_diff_{i}\" for i in range(feat_vec_size)]\n",
    "\n",
    "    feat_vec_df = pd.DataFrame(columns=col_names)\n",
    "\n",
    "    # Calculate each feature vector and adds it to the dataframe\n",
    "    for i in range(len(df)):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"\\rProcessing pair {i}/{len(df)} (as test data)\", end=\"\")\n",
    "\n",
    "        s1_fv = get_feature_vector(df[\"text_1\"][i]).flatten()\n",
    "        s2_fv = get_feature_vector(df[\"text_2\"][i]).flatten()\n",
    "        fv_diff = np.abs(s1_fv - s2_fv)\n",
    "        \n",
    "        row = np.concatenate((s1_fv, s2_fv, fv_diff), axis=0)\n",
    "\n",
    "        feat_vec_df = feat_vec_df._append(pd.DataFrame([row], columns=col_names), ignore_index=True)\n",
    "\n",
    "    # Outputs the final csv\n",
    "    feat_vec_df.to_csv(f\"{name}_feature_vectors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_dataset(df: pd.DataFrame, test: bool = False):\n",
    "    # Returns the feature vector dataset - type depending on the input\n",
    "    if not test:\n",
    "        return FeatureDataset(df)\n",
    "    else:\n",
    "        return TestFeatureDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier():\n",
    "    # Training algorithm\n",
    "    # First loads training and testing datasets\n",
    "    print(\"Beginning Training\")\n",
    "    feat_vec_train_df = pd.read_csv(\"training_feature_vectors.csv\")\n",
    "    feat_vec_eval_df = pd.read_csv(\"eval_feature_vectors.csv\")\n",
    "    feat_vec_train_ds = get_feat_dataset(feat_vec_train_df)\n",
    "    feat_vec_eval_ds = get_feat_dataset(feat_vec_eval_df)\n",
    "    feat_vec_train_dl = DataLoader(feat_vec_train_ds, batch_size=16, shuffle=True)\n",
    "    feat_vec_test_dl = DataLoader(feat_vec_eval_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Defines the model, loss function, and optimiser\n",
    "    feat_vec_size = feat_vec_train_df.shape[1] - 1\n",
    "    model = BinaryClassifier(feat_vec_size)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "    # Defines other hyperparameters\n",
    "    epochs = 200\n",
    "    threshold = 0\n",
    "\n",
    "    # Initialises the variable used for memory\n",
    "    current_best = (None, 0.0, -1)\n",
    "\n",
    "    # Main training loop\n",
    "    for i in range(epochs):\n",
    "        # Loop makes prediction, calculates loss, and then backpropagates\n",
    "        loss_list = []\n",
    "        model.train()\n",
    "        for fv, label in feat_vec_train_dl:\n",
    "            optimiser.zero_grad()\n",
    "            output = model(fv)\n",
    "            loss = criterion(output, label)\n",
    "            loss_list.append(loss.detach().numpy())\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        print(f\"Mean Training Loss for Epoch {i}: {np.mean(loss_list)}\")\n",
    "\n",
    "        # Collect statistics on the eval set (same logic as below)\n",
    "        loss_list = []\n",
    "        preds = []\n",
    "        true_labels = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for fv, label in feat_vec_test_dl:\n",
    "                output = model(fv)\n",
    "                loss = criterion(output, label)\n",
    "                loss_list.append(loss.detach().numpy())\n",
    "                preds.append(1 if output[0] > threshold else 0)\n",
    "                true_labels.append(label.detach().numpy())\n",
    "\n",
    "        # Collect simple metrics\n",
    "        correct = 0\n",
    "        TPs, FPs, FNs, TNs = 0, 0, 0, 0\n",
    "        for j in range(len(true_labels)):\n",
    "            if true_labels[j] == preds[j]:\n",
    "                correct += 1\n",
    "                if true_labels[j] == 1:\n",
    "                    TPs += 1\n",
    "                else:\n",
    "                    TNs += 1\n",
    "            else:\n",
    "                if true_labels[j] == 1:\n",
    "                    FNs += 1\n",
    "                else:\n",
    "                    FPs += 1\n",
    "\n",
    "        # Calculate complex metrics\n",
    "        accuracy = correct / len(true_labels)\n",
    "        recall = 0 if TPs + FNs == 0 else TPs / (TPs + FNs)\n",
    "        precision = 0 if TPs + FPs == 0 else TPs / (TPs + FPs)\n",
    "        f1 = 0 if precision + recall == 0 else 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        # Outputs results\n",
    "        print(f\"Testing Stats for Epoch {i}\")\n",
    "        print(f\"    Mean Loss: {np.mean(loss_list)}\")\n",
    "        print(f\"    Accuracy: {accuracy}\")\n",
    "        print(f\"    _____________________________\")\n",
    "        print(f\"    |True\\Pred|Positive|Negative|\")\n",
    "        print(f\"    |---------|--------|--------|\")\n",
    "        print(f\"    |Positive |TPs: {TPs}|FNs: {FNs}|\")\n",
    "        print(f\"    |---------|--------|--------|\")\n",
    "        print(f\"    |Negative |FPs: {FPs}|TNs: {TNs}|\")\n",
    "        print(f\"    |---------|--------|--------|\")\n",
    "        print(f\"    \")\n",
    "        print(f\"    Precision: {precision}\")\n",
    "        print(f\"    Recall: {recall}\")\n",
    "        print(f\"    F1 Score: {f1}\")\n",
    "\n",
    "        # Checks to see if the current state is the best model\n",
    "        if accuracy > current_best[1]:\n",
    "            current_best = (copy.deepcopy(model), accuracy, i)\n",
    "\n",
    "    # Outputs the best model's accuracy, and then returns the best model\n",
    "    print(f\"Got best performance at epoch {current_best[2]} with accuracy {current_best[1]}\")\n",
    "    \n",
    "    return current_best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(model, datapath=\"eval_feature_vectors.csv\"):\n",
    "    # Function for evaluating the model on the eval dataset\n",
    "    # Reads the csv and converts to data loader\n",
    "    feat_vec_df = pd.read_csv(datapath)\n",
    "    feat_vec_ds = get_feat_dataset(feat_vec_df)\n",
    "    feat_vec_dl = DataLoader(feat_vec_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Defines variables and functions for statistics (BCE for loss function)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    loss_list = []\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    threshold = 0\n",
    "\n",
    "    # Ensures eval mode then loops through the dataset to get predictions and other stats\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for fv, label in feat_vec_dl:\n",
    "            output = model(fv)\n",
    "            loss = criterion(output, label)\n",
    "            loss_list.append(loss.detach().numpy())\n",
    "            preds.append(1 if output[0] > threshold else 0)\n",
    "            true_labels.append(label.detach().numpy())\n",
    "\n",
    "    # Calculates simple metrics\n",
    "    correct = 0\n",
    "    TPs = 0\n",
    "    FPs = 0\n",
    "    TNs = 0\n",
    "    FNs = 0\n",
    "\n",
    "    for i in range(len(true_labels)):\n",
    "        if true_labels[i] == preds[i]:\n",
    "            correct += 1\n",
    "            if true_labels[i] == 1:\n",
    "                TPs += 1\n",
    "            else:\n",
    "                TNs += 1\n",
    "        else:\n",
    "            if true_labels[i] == 1:\n",
    "                FNs += 1\n",
    "            else:\n",
    "                FPs += 1\n",
    "\n",
    "    # Calculates complex metrics\n",
    "    accuracy = correct / len(true_labels)\n",
    "    recall = 0 if TPs + FNs == 0 else TPs / (TPs + FNs)\n",
    "    precision = 0 if TPs + FPs == 0 else TPs / (TPs + FPs)\n",
    "    f1 = 0 if precision + recall == 0 else 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # Outputs results\n",
    "    print(f\"Testing Stats for Classifier\")\n",
    "    print(f\"    Mean Loss: {np.mean(loss_list)}\")\n",
    "    print(f\"    Accuracy: {accuracy}\")\n",
    "    print(f\"    _____________________________\")\n",
    "    print(f\"    |True\\Pred|Positive|Negative|\")\n",
    "    print(f\"    |---------|--------|--------|\")\n",
    "    print(f\"    |Positive |TPs: {TPs}|FNs: {FNs}|\")\n",
    "    print(f\"    |---------|--------|--------|\")\n",
    "    print(f\"    |Negative |FPs: {FPs}|TNs: {TNs}|\")\n",
    "    print(f\"    |---------|--------|--------|\")\n",
    "    print(f\"    \")\n",
    "    print(f\"    Precision: {precision}\")\n",
    "    print(f\"    Recall: {recall}\")\n",
    "    print(f\"    F1 Score: {f1}\")\n",
    "\n",
    "    return (accuracy, recall, precision, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(model, data_path):\n",
    "    # Simple function to test the classifier\n",
    "    # Takes the test feature vectors (based on supplied data path) and loads it into a dataset\n",
    "    # Then it loops hrough each input and sets the prediction\n",
    "    feat_vec_df = pd.read_csv(data_path)\n",
    "    test_ds = get_feat_dataset(feat_vec_df, True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    threshold = 0\n",
    "\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X in test_dl:\n",
    "            output = model(X)\n",
    "            preds.append(1 if output[0] > threshold else 0)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook \"Engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Mode Switch\n",
    "generate_new_feat_vecs = False\n",
    "inference_mode = True\n",
    "run_next = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "if run_next:\n",
    "    if generate_new_feat_vecs:\n",
    "        create_feature_vecs(\"Data/train.csv\", \"training\")\n",
    "        create_feature_vecs(\"Data/dev.csv\", \"eval\")\n",
    "        create_feature_vecs_test(\"Data/test.csv\", \"testing\")\n",
    "    if not inference_mode:\n",
    "        train_time_start = time.time()\n",
    "        classifier = train_classifier()\n",
    "        print(f\"Training time: {time.time() - train_time_start}\")\n",
    "        torch.save(classifier, \"solution_1_classifier.pth\")\n",
    "        results = eval_classifier(classifier)\n",
    "    else:\n",
    "        classifier = torch.load(\"solution_1_classifier.pth\", weights_only=False)\n",
    "        eval_classifier(classifier)\n",
    "        predictions = test_classifier(classifier, \"testing_feature_vectors.csv\")\n",
    "        preds_df = pd.DataFrame(predictions, columns=[\"prediction\"])\n",
    "        preds_df.to_csv(\"Group_17_A.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m new_path_is_test_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_path_is_test_data:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mcreate_feature_vecs_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     classifier \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution_1_classifier.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m test_classifier(classifier, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_data_feature_vectors.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m, in \u001b[0;36mcreate_feature_vecs_test\u001b[0;34m(file_path, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_feature_vecs_test\u001b[39m(file_path, name):\n\u001b[1;32m      2\u001b[0m     feat_vec_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m43\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     col_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfv_1_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(feat_vec_size)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfv_2_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(feat_vec_size)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfv_diff_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(feat_vec_size)]\n\u001b[1;32m      6\u001b[0m     feat_vec_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mcol_names)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "# Run for new data\n",
    "new_path = \"\"\n",
    "new_path_is_test_data = True\n",
    "if new_path_is_test_data:\n",
    "    create_feature_vecs_test(new_path, \"new_data\")\n",
    "    classifier = torch.load(\"solution_1_classifier.pth\", weights_only=False)\n",
    "    predictions = test_classifier(classifier, \"new_data_feature_vectors.csv\")\n",
    "    preds_df = pd.DataFrame(predictions, columns=[\"prediction\"])\n",
    "    print(preds_df)\n",
    "else:\n",
    "    create_feature_vecs(new_path, \"new_data\")\n",
    "    classifier = torch.load(\"solution_1_classifier.pth\", weights_only=False)\n",
    "    eval_classifier(classifier, \"new_data_feature_vectors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
